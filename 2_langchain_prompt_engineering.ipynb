{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d45136",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "In this notebook, we will explore the concept of prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82e6f6",
   "metadata": {},
   "source": [
    "## Structure of a Prompt\n",
    "A prompt is a structured input that guides the model's response. It typically consists of:\n",
    "- **Instruction**: A clear directive on what the model should do. Typically how it should use inputs and or external information to produce the desired output.\n",
    "- **External information or context**: Additional data that we can manually provide the model prompt with, retrieve from a vector database, or retrieve from a web search.\n",
    "- **User input**: the specific query that the user inputs.\n",
    "- **Output indicator**: the beginning of the model's response, which can be a specific phrase or format that the model should follow. For example, \"The answer is:\" or \"Response:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8334084c",
   "metadata": {},
   "source": [
    "Not all prompts will have all these components, but a well-structured prompt will typically include at least two or more of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9b4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fa4a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee97e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, \n",
    "cognitive psychologist, known for his work on artificial neural networks which earned him the title as the \n",
    "\"Godfather of AI\". Hinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, \n",
    "he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing \n",
    "his departure from Google in May 2023, citing concerns about the risks of artificial intelligence (AI) technology.\n",
    "\n",
    "In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n",
    "With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 \n",
    "that popularised the backpropagation algorithm for training multi-layer neural networks, although they were \n",
    "not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community.\n",
    "The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky \n",
    "and Ilya Sutskever for the ImageNet challenge 2012[22] was a breakthrough in the field of computer vision.\n",
    "\n",
    "Hinton received the 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with \n",
    "Yoshua Bengio and Yann LeCun, for their work on deep learning. They are sometimes referred to as the \n",
    "\"Godfathers of Deep Learning\", and have continued to give public talks together. He was also awarded \n",
    "the 2024 Nobel Prize in Physics, shared with John Hopfield.\n",
    "\n",
    "Question: Which important achievements did he get?\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b888aaeb",
   "metadata": {},
   "source": [
    "In this example, we have:\n",
    "* **Instruction**: \"Answer the question based on the provided context.\"\n",
    "* **External information or context**: The provided text about Hinton.\n",
    "* **User input**: \"Which contribution did he provide?\"\n",
    "* **Output indicator**: \"Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febe1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b03058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geoffrey Hinton received the following important achievements:\n",
      "\n",
      "1. The 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with Yoshua Bengio and Yann LeCun, for their work on deep learning.\n",
      "2. The 2024 Nobel Prize in Physics, shared with John Hopfield.\n"
     ]
    }
   ],
   "source": [
    "# make a response from our prompt\n",
    "answer = llm.invoke(prompt)   \n",
    "# print the response\n",
    "print(answer.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbf9bc",
   "metadata": {},
   "source": [
    "We wouldn't typically know the user input in advance. So insted of writing the full prompt, we can use a template to create it dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea479d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, \n",
    "cognitive psychologist, known for his work on artificial neural networks which earned him the title as the \n",
    "\"Godfather of AI\". Hinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, \n",
    "he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing \n",
    "his departure from Google in May 2023, citing concerns about the risks of artificial intelligence (AI) technology.\n",
    "\n",
    "In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n",
    "With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 \n",
    "that popularised the backpropagation algorithm for training multi-layer neural networks, although they were \n",
    "not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community.\n",
    "The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky \n",
    "and Ilya Sutskever for the ImageNet challenge 2012[22] was a breakthrough in the field of computer vision.\n",
    "\n",
    "Hinton received the 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with \n",
    "Yoshua Bengio and Yann LeCun, for their work on deep learning. They are sometimes referred to as the \n",
    "\"Godfathers of Deep Learning\", and have continued to give public talks together. He was also awarded \n",
    "the 2024 Nobel Prize in Physics, shared with John Hopfield.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1667355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630bd80",
   "metadata": {},
   "source": [
    "the output_parser is used to parse the model's response into a specific format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d38c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geoffrey Hinton received the following important achievements:\n",
      "\n",
      "1. The 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with Yoshua Bengio and Yann LeCun, for their work on deep learning.\n",
      "2. The 2024 Nobel Prize in Physics, shared with John Hopfield.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({\"query\": \"Which important achievements did he get?\"})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c716136",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting. \n",
    "It is ideal for what we call _few-shot learning_ using our prompt. \n",
    "To give some context, the primary sources of knoledge for LLMs are:\n",
    "+ __Parametric knowledge__: it is been learned during the training phase and is stored in the model's parameters.\n",
    "+ __Source knowledge__: it is given to the input model at inference time, e.g via the prompt.\n",
    "\n",
    "This means that we can use the prompt to provide the model with additional context or examples as _source knowledge_ that it can use to generate a more accurate response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e289a7",
   "metadata": {},
   "source": [
    "### Few-Shot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc19877b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Frequently Asked Questions (FAQ)**\n",
       "\n",
       "### Shipping and Tracking\n",
       "\n",
       "#### Q1: Do you ship internationally?\n",
       "A1: **Yes, we ship worldwide.** Shipping times and costs vary depending on the destination.\n",
       "\n",
       "#### Q2: How can I track my order?\n",
       "A2: **Once your order ships, you’ll receive a tracking number via email.** You can also track orders through your account dashboard.\n",
       "\n",
       "### Returns and Refunds\n",
       "\n",
       "#### Q3: What is your return policy?\n",
       "A3: **You can return items within 30 days of receipt for a full refund.** Items must be in original condition and packaging."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "template = \"\"\"Create a FQA in Markdown Format on the following questions and answers,\n",
    "    Q1: Do you ship internationally?,\n",
    "    A1: Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\n",
    "    Q2: How can I track my order?,\n",
    "    A2: Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\n",
    "    Q3: What is your return policy?,\n",
    "    A3: You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[] # No input variables needed for this template\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({})\n",
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376793a",
   "metadata": {},
   "source": [
    "The output are ok but what if we want to format the output in aspecific way? We can give the model some examples of the desired output format in the prompt. This is called few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eda1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Create a structured Markdown FAQ with links, headers, and bullet points based on the following questions and answers.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Example Input:\n",
    "Q1: Do you ship internationally?\n",
    "A1: Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\n",
    "Q2: How can I track my order?\n",
    "A2: Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\n",
    "Q3: What is your return policy?\n",
    "A3: You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\n",
    "\n",
    "Example Output:\n",
    "# Frequently Asked Questions\n",
    "## Shipping\n",
    "- **Do you ship internationally?**  \n",
    "  Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\n",
    "- **How can I track my order?**  \n",
    "  Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\n",
    "## Returns\n",
    "- **What is your return policy?**  \n",
    "  You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\n",
    "\n",
    "Now, create a similar FAQ based on the following questions and answers:\n",
    "Q1: What payment methods are accepted?,\n",
    "A1: We accept Visa, MasterCard, PayPal, Apple Pay, and Klarna (Buy Now, Pay Later in select countries).,\n",
    "Q2: Are your products eco-friendly?,\n",
    "A2: Yes, we use sustainable materials and practices in our production process.,\n",
    "Q3: Can I change or cancel my order after placing it?,\n",
    "A3: We can modify or cancel orders within 1 hour of purchase. Contact our support team immediately for assistance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e278d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Frequently Asked Questions\n",
       "## Payment and Ordering\n",
       "- **What payment methods are accepted?**  \n",
       "  We accept Visa, MasterCard, PayPal, Apple Pay, and Klarna (Buy Now, Pay Later in select countries).\n",
       "- **Can I change or cancel my order after placing it?**  \n",
       "  We can modify or cancel orders within 1 hour of purchase. Contact our support team immediately for assistance.\n",
       "\n",
       "## Products and Sustainability\n",
       "- **Are your products eco-friendly?**  \n",
       "  Yes, we use sustainable materials and practices in our production process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[] # No input variables needed for this template\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({})\n",
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681aff14",
   "metadata": {},
   "source": [
    "We got a more readable output by adding a few-shot example to the prompt.\n",
    "In Langchain, we can also use FewShotPromptTemplate to create a few-shot prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8f0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3979492",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        'input': (\n",
    "            \"Q1: Do you ship internationally?\\n\"\n",
    "            \"A1: Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\\n\"\n",
    "        ),\n",
    "        'output': (\n",
    "            \"## Shipping\\n\"\n",
    "            \"- **Do you ship internationally?**  \\n\"\n",
    "            \"  Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\\n\"\n",
    "        )\n",
    "    },\n",
    "    {        'input': (\n",
    "            \"Q2: How can I track my order?\\n\"\n",
    "            \"A2: Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\\n\"\n",
    "        ),\n",
    "        'output': (\n",
    "            \"## Tracking\\n\"\n",
    "            \"- **How can I track my order?**  \\n\"\n",
    "            \"  Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'input': (\n",
    "            \"Q3: What is your return policy?\\n\"\n",
    "            \"A3: You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\\n\"\n",
    "        ),\n",
    "        'output': (\n",
    "            \"## Returns\\n\"\n",
    "            \"- **What is your return policy?**  \\n\"\n",
    "            \"  You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\\n\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1bb17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create template \n",
    "example_template = \"\"\"Example input:\n",
    "{input}\n",
    "\n",
    "Example Output:\n",
    "# Frequently Asked Questions\\n\\n\n",
    "{output}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46314fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88134a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prefix\n",
    "prefix = \"\"\"Create a structured Markdown FAQ with links, headers, and bullet points based on the following questions and answers.\n",
    "\n",
    "**Example:**\"\"\"\n",
    "\n",
    "# User input format and instructions\n",
    "suffix = \"\"\"\n",
    "Now, create a similar FAQ based on the following questions and answers:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2022c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the few-shot prompt template\n",
    "few_shot = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4face85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"Q1: What payment methods are accepted?,\n",
    "A1: We accept Visa, MasterCard, PayPal, Apple Pay, and Klarna (Buy Now, Pay Later in select countries).,\n",
    "Q2: Are your products eco-friendly?,\n",
    "A2: Yes, we use sustainable materials and practices in our production process.,\n",
    "Q3: Can I change or cancel my order after placing it?,\n",
    "A3: We can modify or cancel orders within 1 hour of purchase. Contact our support team immediately for assistance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b82780",
   "metadata": {},
   "source": [
    "Now let's see what prompt this creates when we feed in a user query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a379e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a structured Markdown FAQ with links, headers, and bullet points based on the following questions and answers.\n",
      "\n",
      "**Example:**\n",
      "Example input:\n",
      "Q1: Do you ship internationally?\n",
      "A1: Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\n",
      "\n",
      "\n",
      "Example Output:\n",
      "# Frequently Asked Questions\n",
      "\n",
      "\n",
      "## Shipping\n",
      "- **Do you ship internationally?**  \n",
      "  Yes, we ship worldwide. Shipping times and costs vary depending on the destination.\n",
      "\n",
      "\n",
      "Example input:\n",
      "Q2: How can I track my order?\n",
      "A2: Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\n",
      "\n",
      "\n",
      "Example Output:\n",
      "# Frequently Asked Questions\n",
      "\n",
      "\n",
      "## Tracking\n",
      "- **How can I track my order?**  \n",
      "  Once your order ships, you’ll receive a tracking number via email. You can also track orders through your account dashboard.\n",
      "\n",
      "\n",
      "Example input:\n",
      "Q3: What is your return policy?\n",
      "A3: You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\n",
      "\n",
      "\n",
      "Example Output:\n",
      "# Frequently Asked Questions\n",
      "\n",
      "\n",
      "## Returns\n",
      "- **What is your return policy?**  \n",
      "  You can return items within 30 days of receipt for a full refund. Items must be in original condition and packaging.\n",
      "\n",
      "\n",
      "\n",
      "Now, create a similar FAQ based on the following questions and answers:\n",
      "Q1: What payment methods are accepted?,\n",
      "A1: We accept Visa, MasterCard, PayPal, Apple Pay, and Klarna (Buy Now, Pay Later in select countries).,\n",
      "Q2: Are your products eco-friendly?,\n",
      "A2: Yes, we use sustainable materials and practices in our production process.,\n",
      "Q3: Can I change or cancel my order after placing it?,\n",
      "A3: We can modify or cancel orders within 1 hour of purchase. Contact our support team immediately for assistance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = few_shot.format(input=user_input)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c988bf",
   "metadata": {},
   "source": [
    "We can use a chain to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e46761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Frequently Asked Questions\n",
       "\n",
       "## Payment and Ordering\n",
       "- **What payment methods are accepted?**  \n",
       "  We accept Visa, MasterCard, PayPal, Apple Pay, and Klarna (Buy Now, Pay Later in select countries).\n",
       "\n",
       "## Sustainability\n",
       "- **Are your products eco-friendly?**  \n",
       "  Yes, we use sustainable materials and practices in our production process.\n",
       "\n",
       "## Order Management\n",
       "- **Can I change or cancel my order after placing it?**  \n",
       "  We can modify or cancel orders within 1 hour of purchase. Contact our support team immediately for assistance.\n",
       "\n",
       "Note: This FAQ is a basic structure and can be expanded to include more questions and answers as needed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = few_shot | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({\"input\": user_input})\n",
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9ce16",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we have learnt:\n",
    "- how we can use prompt engineering to guide the model's response\n",
    "- how to structure a prompt with an instruction, external information, user input, and output indicator\n",
    "- how to make use of few-shot prompting to provide examples of the desired output format\n",
    "- how to use LangChain's FewShotPromptTemplate to create a few-shot prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
