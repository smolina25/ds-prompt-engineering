{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f55fdd8",
   "metadata": {},
   "source": [
    "# Intro to LangChain\n",
    "LangChain is a popular framework that allows you to quickly build applications and pipelines of Large Language Models (LLMs). You can use it to create chatbots, RAGs, agents and much more.\n",
    "\n",
    "The main idea of the library is that we can create a _chain_ of different components to create more complex applications. These _chains_ (you can think of them as pipelines) can be made up of various components such as:\n",
    "- **Prompts templates**: Prompts templates are templates to generate different type of prompts. Like chat prompts, question answering prompts, etc.\n",
    "- **LLMs**: Large Language Models are the core of LangChain. You can use any LLM that is compatible with the library, like OpenAI, Hugging Face, LLama, etc.\n",
    "- **Tools**: Tools are functions that can be used by the LLM to perform specific tasks. For example, you can use a tool to search the web, or to access a database.\n",
    "- **Agents**: Agents are components that can use LLMs and tools to perform specific tasks. They can be used to create chatbots, **R**etrieval **A**ugumentation **G**eneration (RAGs), etc.\n",
    "- **Retrievers**: Retrievers are components that can be used to retrieve information from a database or a knowledge base. They can be used to create RAGs, or to retrieve information from a database.  \n",
    "- **Memory**: Memory is a component that can be used to store information about the conversation. It can be used to create chatbots that can remember previous conversations, or to create RAGs that can remember previous queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f782a95",
   "metadata": {},
   "source": [
    "## Using LLMs in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d041d",
   "metadata": {},
   "source": [
    "LangChain supports a wide range of providers for LLMs, including OpenAI, Hugging Face, Groq,  LLama and many others.\n",
    "\n",
    "Let's start our exploration of LangChain by using Grog integration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb61e82",
   "metadata": {},
   "source": [
    "### Groq Integration\n",
    "Groq is a provider of LLMs that offers high-performance inference capabilities. To use Groq with LangChain, you need to set up your API key in the `.env` file. Follow the steps in the README.md file to set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80c0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d202bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/santiagomolina/aipm-1711/ds-prompt-engineering\n",
      ".env file exists: True\n",
      ".env content preview: GROQ_API_KEY=gsk_rz78Ke67c4qTh8emBkTXWGdyb3FYORCLm\n",
      "load_dotenv() returned: True\n",
      "GROQ_API_KEY in environment: True\n",
      "API Key preview: gsk_rz78Ke67c4qTh8em...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Show current directory\n",
    "print(f\"Current directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if .env exists\n",
    "env_file = Path.cwd() / '.env'\n",
    "print(f\".env file exists: {env_file.exists()}\")\n",
    "\n",
    "# If it exists, show its content (first 50 chars)\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        content = f.read()\n",
    "        print(f\".env content preview: {content[:50]}\")\n",
    "\n",
    "# Load the .env file\n",
    "loaded = load_dotenv()\n",
    "print(f\"load_dotenv() returned: {loaded}\")\n",
    "\n",
    "# Check if the key is in environment\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "print(f\"GROQ_API_KEY in environment: {bool(api_key)}\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"API Key preview: {api_key[:20]}...\")\n",
    "else:\n",
    "    print(\"API Key NOT found in environment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0250861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9b45a",
   "metadata": {},
   "source": [
    "#### Load Credentials from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8777880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdf171",
   "metadata": {},
   "source": [
    "#### Defining the LLM (Using Groq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f8df8",
   "metadata": {},
   "source": [
    "We can define the LLM using the [`ChatGroq`](https://python.langchain.com/docs/integrations/chat/groq/) class from the `langchain_groq` module. \n",
    "This class allows us to specify:\n",
    "+ the model - below we use `llama-3.1-8b-instant`\n",
    "+ the temperature - we set it to `0.1` for more deterministic responses\n",
    "+ the maximum tokens - we set it to `512` to limit the response length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e42b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad1d0",
   "metadata": {},
   "source": [
    "#### Build prompt template\n",
    "A prompt is a set of instructions or input provided by a user to an LLM to guide its response. It helps the model understand the context and generate relevant output. In LangChain, we can create a prompt template using the `PromptTemplate` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ddde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c0a9d",
   "metadata": {},
   "source": [
    "The __input_variables__ are defined in the template using curly braces '{}'. This allows us to dynamically insert values into the template when we use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884340c",
   "metadata": {},
   "source": [
    "#### Define Chain\n",
    "A chain is sequence of components that are executed in order to produce a final output. In LangChain, we can use the pipe symbol `|` to define a chain of components. The output of one component is passed as input to the next component in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6cc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b708f0f",
   "metadata": {},
   "source": [
    "#### Invoke the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e07785",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the backpropagation algorithm?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c1daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke(input={\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c5f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Backpropagation Algorithm**\n",
      "\n",
      "The backpropagation algorithm is a widely used method for training artificial neural networks (ANNs). It is an optimization technique used to minimize the error between the network's predictions and the actual output. The algorithm is based on the concept of gradient descent, which iteratively adjusts the network's weights and biases to reduce the error.\n",
      "\n",
      "**How Backpropagation Works**\n",
      "\n",
      "Here's a step-by-step explanation of the backpropagation algorithm:\n",
      "\n",
      "1. **Forward Pass**: The network processes the input data and produces an output.\n",
      "2. **Error Calculation**: The difference between the predicted output and the actual output is calculated, resulting in an error value.\n",
      "3. **Backward Pass**: The error is propagated backwards through the network, adjusting the weights and biases of each layer to minimize the error.\n",
      "4. **Weight Update**: The weights and biases are updated based on the error gradient, using an optimization algorithm such as stochastic gradient descent (SGD) or Adam.\n",
      "5. **Repeat**: Steps 1-4 are repeated until the network converges or a stopping criterion is reached.\n",
      "\n",
      "**Key Components**\n",
      "\n",
      "* **Activation Functions**: Used to introduce non-linearity into the network, such as sigmoid, ReLU, or tanh.\n",
      "* **Loss Function**: Measures the difference between the predicted output and the actual output, such as mean squared error (MSE) or cross-entropy.\n",
      "* **Optimization Algorithm**: Used to update the weights and biases, such as SGD or Adam.\n",
      "\n",
      "**Example Use Case**\n",
      "\n",
      "Suppose we want to train a neural network to classify images of dogs and cats. We would:\n",
      "\n",
      "1. Collect a dataset of images with labels (dog or cat).\n",
      "2. Design a neural network architecture with multiple layers.\n",
      "3. Use backpropagation to train the network, adjusting the weights and biases to minimize the error between the predicted output and the actual output.\n",
      "4. Evaluate the network's performance on a test dataset.\n",
      "\n",
      "**Code Example**\n",
      "\n",
      "Here's a simple example of backpropagation in Python using the Keras library:\n",
      "```python\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "from keras.optimizers import SGD\n",
      "from keras.datasets import mnist\n",
      "\n",
      "# Load MNIST dataset\n",
      "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "\n",
      "# Normalize input data\n",
      "x_train = x_train / 255.0\n",
      "x_test = x_test / 255.0\n",
      "\n",
      "# Design neural network architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation='relu\n"
     ]
    }
   ],
   "source": [
    "print(answer.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3203d797",
   "metadata": {},
   "source": [
    "If we'd like to ask multiple questions we can by passing a list of dictionary objects, where the dictionaries must contain the input variable set in our prompt template (\"question\") that is mapped to the question we'd like to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c306b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [ \n",
    "    {\"question\": \"What is the backpropagation algorithm?\"},\n",
    "    {\"question\": \"What is the purpose of the activation function in a neural network?\"},\n",
    "    {\"question\": \"What is the difference between supervised and unsupervised learning?\"},\n",
    "    {\"question\": \"Explain the concept of overfitting in machine learning.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4f0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = chain.batch(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722097ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Question: What is the backpropagation algorithm?\n",
      "Answer: **Backpropagation Algorithm**\n",
      "\n",
      "The backpropagation algorithm is a widely used method for training artificial neural networks (ANNs). It's an essential component of deep learning and is used to optimize the network's weights and biases to minimize the error between the predicted output and the actual output.\n",
      "\n",
      "**How Backpropagation Works**\n",
      "\n",
      "The backpropagation algorithm works as follows:\n",
      "\n",
      "1. **Forward Pass**: The input data is fed into the neural network, and the output is calculated by propagating the input through the network.\n",
      "2. **Error Calculation**: The difference between the predicted output and the actual output is calculated, which is known as the error.\n",
      "3. **Backward Pass**: The error is propagated backwards through the network, adjusting the weights and biases of each layer to minimize the error.\n",
      "4. **Weight Update**: The weights and biases are updated based on the error and the learning rate.\n",
      "\n",
      "**Mathematical Formulation**\n",
      "\n",
      "The backpropagation algorithm can be mathematically formulated as follows:\n",
      "\n",
      "Let `L` be the loss function, `y` be the actual output, and `y_pred` be the predicted output.\n",
      "\n",
      "1. **Forward Pass**:\n",
      "   - `y_pred = f(x, w, b)`\n",
      "   - `L = L(y, y_pred)`\n",
      "\n",
      "2. **Backward Pass**:\n",
      "   - `dL/dy_pred = dL/dy_pred * dy_pred/dy`\n",
      "   - `dL/dw = dL/dy_pred * dy_pred/dw`\n",
      "   - `dL/db = dL/dy_pred * dy_pred/db`\n",
      "\n",
      "3. **Weight Update**:\n",
      "   - `w_new = w_old - learning_rate * dL/dw`\n",
      "   - `b_new = b_old - learning_rate * dL/db`\n",
      "\n",
      "**Example Use Case**\n",
      "\n",
      "Suppose we have a simple neural network with one input layer, one hidden layer, and one output layer. The input is a 2D vector `[x1, x2]`, and the output is a scalar `y`. The hidden layer has two neurons with weights `w1` and `w2`, and biases `b1` and `b2`.\n",
      "\n",
      "The forward pass would calculate the output of the hidden layer and the output layer:\n",
      "\n",
      "`y_pred = f(x1*w1 + x2*w2 + b1, x1*w3 + x2*w4 + b2)`\n",
      "\n",
      "The backward pass would calculate the error gradients:\n",
      "\n",
      "`dL/dw1 = dL/dy_pred\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: What is the purpose of the activation function in a neural network?\n",
      "Answer: The primary purpose of the activation function in a neural network is to introduce non-linearity into the model. This is crucial because most neural networks are composed of multiple layers of interconnected nodes (neurons), and if each node simply multiplied the inputs, the output would be a linear combination of the inputs.\n",
      "\n",
      "Without non-linearity, the neural network would only be able to learn linear relationships between inputs and outputs, which is not sufficient for most real-world problems. Activation functions introduce a non-linear transformation to the output of each node, allowing the network to learn more complex relationships between inputs and outputs.\n",
      "\n",
      "Some key benefits of activation functions include:\n",
      "\n",
      "1. **Non-linearity**: Activation functions introduce non-linearity, enabling the network to learn complex relationships between inputs and outputs.\n",
      "2. **Differentiation**: Activation functions allow the network to differentiate between different inputs, which is essential for learning and generalization.\n",
      "3. **Sigmoidal behavior**: Many activation functions, such as the sigmoid and ReLU (Rectified Linear Unit), exhibit sigmoidal behavior, which helps the network to learn and represent complex relationships.\n",
      "\n",
      "Common activation functions used in neural networks include:\n",
      "\n",
      "1. **Sigmoid**: Maps the input to a value between 0 and 1.\n",
      "2. **ReLU (Rectified Linear Unit)**: Maps all negative values to 0 and all positive values to the same value.\n",
      "3. **Tanh (Hyperbolic Tangent)**: Maps the input to a value between -1 and 1.\n",
      "4. **Leaky ReLU**: A variant of ReLU that allows a small fraction of the input to pass through even when it's negative.\n",
      "5. **Softmax**: Maps the input to a probability distribution over multiple classes.\n",
      "\n",
      "In summary, the activation function is a crucial component of a neural network, introducing non-linearity, differentiation, and sigmoidal behavior, which enables the network to learn and represent complex relationships between inputs and outputs.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: What is the difference between supervised and unsupervised learning?\n",
      "Answer: The primary difference between supervised and unsupervised learning lies in the type of data used to train the model and the goal of the learning process.\n",
      "\n",
      "**Supervised Learning:**\n",
      "\n",
      "In supervised learning, the model is trained on labeled data, where each example is associated with a target output or response variable. The goal is to learn a mapping between the input data and the corresponding output labels, so that the model can make predictions on new, unseen data. The model is \"supervised\" by the labeled data, which provides feedback on its performance.\n",
      "\n",
      "Example: Image classification, where the model is trained on images labeled as \"cat,\" \"dog,\" or \"bird,\" and the goal is to predict the class label of a new image.\n",
      "\n",
      "**Unsupervised Learning:**\n",
      "\n",
      "In unsupervised learning, the model is trained on unlabeled data, and the goal is to discover patterns, relationships, or structure in the data. The model does not receive any feedback on its performance, as there are no target outputs to compare against.\n",
      "\n",
      "Example: Clustering, where the model groups similar data points together based on their features, without any prior knowledge of the underlying structure.\n",
      "\n",
      "Key differences:\n",
      "\n",
      "1. **Labeled vs. Unlabeled Data**: Supervised learning uses labeled data, while unsupervised learning uses unlabeled data.\n",
      "2. **Goal**: Supervised learning aims to make predictions on new data, while unsupervised learning aims to discover patterns or structure in the data.\n",
      "3. **Feedback**: Supervised learning receives feedback on its performance, while unsupervised learning does not.\n",
      "\n",
      "In summary, supervised learning is used when you have labeled data and want to make predictions, while unsupervised learning is used when you have unlabeled data and want to discover patterns or structure.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: Explain the concept of overfitting in machine learning.\n",
      "Answer: **Overfitting in Machine Learning:**\n",
      "\n",
      "Overfitting is a fundamental concept in machine learning that occurs when a model is too complex and learns the noise in the training data rather than the underlying patterns. As a result, the model becomes overly specialized to the training data and fails to generalize well to new, unseen data.\n",
      "\n",
      "**Causes of Overfitting:**\n",
      "\n",
      "1. **Complexity**: Models with too many parameters or features can overfit the training data.\n",
      "2. **Small training dataset**: When the training dataset is small, the model may not have enough data to learn the underlying patterns and may instead learn the noise.\n",
      "3. **High variance**: Models with high variance, such as decision trees or neural networks, are more prone to overfitting.\n",
      "\n",
      "**Consequences of Overfitting:**\n",
      "\n",
      "1. **Poor generalization**: The model performs well on the training data but poorly on new, unseen data.\n",
      "2. **High error rate**: The model's error rate is high, indicating that it is not able to learn the underlying patterns.\n",
      "3. **Lack of robustness**: The model is sensitive to small changes in the data and may not be able to handle new data.\n",
      "\n",
      "**Techniques to Prevent Overfitting:**\n",
      "\n",
      "1. **Regularization**: Adding a penalty term to the loss function to discourage large weights.\n",
      "2. **Early stopping**: Stopping the training process when the model's performance on the validation set starts to degrade.\n",
      "3. **Data augmentation**: Increasing the size of the training dataset by applying transformations to the existing data.\n",
      "4. **Cross-validation**: Evaluating the model's performance on multiple subsets of the data to prevent overfitting.\n",
      "5. **Simplifying the model**: Reducing the number of parameters or features in the model.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose we are building a model to predict house prices based on features such as number of bedrooms, square footage, and location. If we include too many features, such as the color of the walls or the type of flooring, the model may overfit the training data and perform poorly on new data. By selecting only the most relevant features, we can prevent overfitting and build a more robust model.\n",
      "\n",
      "**Code Example:**\n",
      "\n",
      "```python\n",
      "from sklearn.datasets import load_breast_cancer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Load the dataset\n",
      "data = load_breast_cancer()\n",
      "X = data.data\n",
      "y = data\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(qs, answers):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Question: {question['question']}\")\n",
    "    print(f\"Answer: {answer.content.strip()}\")\n",
    "    print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
